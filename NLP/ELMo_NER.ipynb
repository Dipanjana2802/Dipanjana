{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ELMo_NER.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNfHfhie+qMQTDeg8WJZmHe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"6PZ2c11ZBhpq","colab_type":"code","colab":{}},"source":["# Data preparation\n","\n","import pandas as pd\n","import numpy as np\n","\n","data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVarp_xrBhn1","colab_type":"code","outputId":"02404a41-70ec-4359-e71e-a8ce2041b0bb","executionInfo":{"status":"ok","timestamp":1581344310487,"user_tz":0,"elapsed":599,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["data = data.fillna(method=\"ffill\")\n","data.tail(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1048565</th>\n","      <td>Sentence: 47958</td>\n","      <td>impact</td>\n","      <td>NN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048566</th>\n","      <td>Sentence: 47958</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048567</th>\n","      <td>Sentence: 47959</td>\n","      <td>Indian</td>\n","      <td>JJ</td>\n","      <td>B-gpe</td>\n","    </tr>\n","    <tr>\n","      <th>1048568</th>\n","      <td>Sentence: 47959</td>\n","      <td>forces</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048569</th>\n","      <td>Sentence: 47959</td>\n","      <td>said</td>\n","      <td>VBD</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048570</th>\n","      <td>Sentence: 47959</td>\n","      <td>they</td>\n","      <td>PRP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048571</th>\n","      <td>Sentence: 47959</td>\n","      <td>responded</td>\n","      <td>VBD</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048572</th>\n","      <td>Sentence: 47959</td>\n","      <td>to</td>\n","      <td>TO</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048573</th>\n","      <td>Sentence: 47959</td>\n","      <td>the</td>\n","      <td>DT</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048574</th>\n","      <td>Sentence: 47959</td>\n","      <td>attack</td>\n","      <td>NN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Sentence #       Word  POS    Tag\n","1048565  Sentence: 47958     impact   NN      O\n","1048566  Sentence: 47958          .    .      O\n","1048567  Sentence: 47959     Indian   JJ  B-gpe\n","1048568  Sentence: 47959     forces  NNS      O\n","1048569  Sentence: 47959       said  VBD      O\n","1048570  Sentence: 47959       they  PRP      O\n","1048571  Sentence: 47959  responded  VBD      O\n","1048572  Sentence: 47959         to   TO      O\n","1048573  Sentence: 47959        the   DT      O\n","1048574  Sentence: 47959     attack   NN      O"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"dQ2y2RF_gwSk","colab_type":"code","outputId":"1124d399-60fe-47af-a254-18f96e57f75c","executionInfo":{"status":"ok","timestamp":1581344312196,"user_tz":0,"elapsed":409,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["words = list(set(data[\"Word\"].values))\n","words.append(\"ENDPAD\")\n","n_words = len(words); n_words"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["35179"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"m9e-ILmsg_Qj","colab_type":"code","outputId":"49ca59bd-dd0c-42f1-b4f5-1f4e5ef26a52","executionInfo":{"status":"ok","timestamp":1581344314312,"user_tz":0,"elapsed":423,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tags = list(set(data[\"Tag\"].values))\n","n_tags = len(tags); n_tags"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"T2ItcX9whG8J","colab_type":"code","colab":{}},"source":["class SentenceGetter(object):\n","    \n","    def __init__(self, data):\n","        self.n_sent = 1\n","        self.data = data\n","        self.empty = False\n","        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n","                                                           s[\"POS\"].values.tolist(),\n","                                                           s[\"Tag\"].values.tolist())]\n","        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","    \n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqUeANefiGi7","colab_type":"code","colab":{}},"source":["getter = SentenceGetter(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gq-zrJxTiJ2D","colab_type":"code","colab":{}},"source":["sent = getter.get_next()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBI4mHtuiLyb","colab_type":"code","outputId":"75dde2b1-41a5-419b-aa6a-653866f8fae4","executionInfo":{"status":"ok","timestamp":1581344400106,"user_tz":0,"elapsed":428,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(sent)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XSN9Z0RyiNjn","colab_type":"code","colab":{}},"source":["sentences = getter.sentences"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jDnLNkteiqRA","colab_type":"text"},"source":["For the use of neural nets (at least with keras, there is no theoretical reason) we need to use equal-lenght input sequences. So we are going to pad our sentences to a length of the longest sentence in our dataset.\n","\n","Also, we need a dictionary of tags to map our labels to numbers."]},{"cell_type":"code","metadata":{"id":"GCaAO024iSzV","colab_type":"code","colab":{}},"source":["longest_sentence = max([len(sent) for sent in sentences])\n","\n","max_len = longest_sentence\n","tag2idx = {t: i for i, t in enumerate(tags)}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPNNBPCdjloY","colab_type":"code","outputId":"2f4ec45e-4d36-4987-93e0-515a3e809d78","executionInfo":{"status":"ok","timestamp":1581344407284,"user_tz":0,"elapsed":450,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tag2idx[\"B-geo\"]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"VSwqZMisjtBX","colab_type":"text"},"source":["To apply the EMLo embedding from tensorflow hub, we have to use strings as input. So we take the tokenized sentences and pad them to the desired length."]},{"cell_type":"code","metadata":{"id":"iRWiOrFujoBo","colab_type":"code","colab":{}},"source":["X = [[w[0] for w in s] for s in sentences]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_Zmlh5Tkd54","colab_type":"code","outputId":"1e229e4f-8546-40aa-ae87-6585824c3aae","executionInfo":{"status":"ok","timestamp":1581344411811,"user_tz":0,"elapsed":527,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["c = 0\n","for s in sentences:\n","  if c<2:\n","    print(s)\n","    c = c+1\n","  else:\n","    break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n","[('Iranian', 'JJ', 'B-gpe'), ('officials', 'NNS', 'O'), ('say', 'VBP', 'O'), ('they', 'PRP', 'O'), ('expect', 'VBP', 'O'), ('to', 'TO', 'O'), ('get', 'VB', 'O'), ('access', 'NN', 'O'), ('to', 'TO', 'O'), ('sealed', 'JJ', 'O'), ('sensitive', 'JJ', 'O'), ('parts', 'NNS', 'O'), ('of', 'IN', 'O'), ('the', 'DT', 'O'), ('plant', 'NN', 'O'), ('Wednesday', 'NNP', 'B-tim'), (',', ',', 'O'), ('after', 'IN', 'O'), ('an', 'DT', 'O'), ('IAEA', 'NNP', 'B-org'), ('surveillance', 'NN', 'O'), ('system', 'NN', 'O'), ('begins', 'VBZ', 'O'), ('functioning', 'VBG', 'O'), ('.', '.', 'O')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UuRAwg0BkfEM","colab_type":"code","colab":{}},"source":["new_X = []\n","for seq in X:\n","    new_seq = []\n","    for i in range(max_len):\n","        try:\n","            new_seq.append(seq[i])\n","        except:\n","            new_seq.append(\"__PAD__\")\n","    new_X.append(new_seq)\n","X = new_X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"68qnh4xSk5v5","colab_type":"code","outputId":"2882ca94-de23-4692-ff36-3509cbc90fe7","executionInfo":{"status":"ok","timestamp":1581344414668,"user_tz":0,"elapsed":313,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(X[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['Iranian', 'officials', 'say', 'they', 'expect', 'to', 'get', 'access', 'to', 'sealed', 'sensitive', 'parts', 'of', 'the', 'plant', 'Wednesday', ',', 'after', 'an', 'IAEA', 'surveillance', 'system', 'begins', 'functioning', '.', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zp4vVBqSlFJg","colab_type":"text"},"source":["And we need to do the same for our tag sequence, but map the string to an integer."]},{"cell_type":"code","metadata":{"id":"BRYBN2Oak8AA","colab_type":"code","colab":{}},"source":["y = [[tag2idx[w[2]] for w in s] for s in sentences]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KQkQapVlK9e","colab_type":"code","colab":{}},"source":["from keras.preprocessing.sequence import pad_sequences\n","y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFX7V49UlUyo","colab_type":"code","outputId":"5094fc5d-5f2c-42d6-e438-212e19c1c28d","executionInfo":{"status":"ok","timestamp":1581344426078,"user_tz":0,"elapsed":321,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(y[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 5  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  9  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0YltF7KtlmW3","colab_type":"text"},"source":["Train and test set splitting"]},{"cell_type":"code","metadata":{"id":"i7GDPSXYlYUE","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, random_state=2018)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZrAaItjvaoC","colab_type":"text"},"source":["The ELMo residual LSTM model"]},{"cell_type":"code","metadata":{"id":"W2unKwrzvWW2","colab_type":"code","colab":{}},"source":["batch_size = 32"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sciOCEoFvlnv","colab_type":"text"},"source":["Initializing the ELMo embedding from tensorflow hub"]},{"cell_type":"code","metadata":{"id":"-4XucfH4vWSp","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8oHjdsD0vWN_","colab_type":"code","colab":{}},"source":["# Initialize the tensorflow session\n","\n","sess = tf.Session()\n","K.set_session(sess)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCy2GXlVv3qB","colab_type":"text"},"source":["Downloading the pretrained model"]},{"cell_type":"code","metadata":{"id":"qGJrvi6LvWDN","colab_type":"code","colab":{}},"source":["elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n","sess.run(tf.global_variables_initializer())\n","sess.run(tf.tables_initializer())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wjWS3FJcwIJO","colab_type":"text"},"source":["Creating a function that takes a sequence of strings and returns a sequence of 1024-dimensional vectors of the ELMo embedding. \n","\n","Next, we will use this function with the Lambda layer of keras to get the embedding sequence"]},{"cell_type":"code","metadata":{"id":"LXnP-GHtwDSC","colab_type":"code","colab":{}},"source":["def ElmoEmbedding(x):\n","    return elmo_model(inputs={\n","                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n","                            \"sequence_len\": tf.constant(batch_size*[max_len])\n","                      },\n","                      signature=\"tokens\",\n","                      as_dict=True)[\"elmo\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8rN4QuqHw_v9","colab_type":"text"},"source":["Next, creating a residual LSTM network with an ELMo embedding layer"]},{"cell_type":"code","metadata":{"id":"NxCG4nkvluGr","colab_type":"code","colab":{}},"source":["from keras.models import Model, Input\n","from keras.layers.merge import add\n","from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1f_3ArbuxwH","colab_type":"code","outputId":"9fb8ce77-4b49-4419-febf-5314cce59b87","executionInfo":{"status":"ok","timestamp":1581344478069,"user_tz":0,"elapsed":4899,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["input_text = Input(shape=(max_len,), dtype=tf.string)\n","embedding = Lambda(ElmoEmbedding, output_shape=(None, None, 1024))(input_text)\n","x = Bidirectional(LSTM(units=512, return_sequences=True,\n","                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n","x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n","                           recurrent_dropout=0.2, dropout=0.2))(x)\n","x = add([x, x_rnn])  # residual connection to the first biLSTM\n","out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ekpv7yHob31e","colab_type":"code","outputId":"47d9b9ee-70c5-4130-8e7c-4956ca525650","executionInfo":{"status":"ok","timestamp":1581343941856,"user_tz":0,"elapsed":7042,"user":{"displayName":"Dipanjana Colab","photoUrl":"","userId":"10332801813381954113"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["#!pip install git+https://www.github.com/keras-team/keras-contrib.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting git+https://www.github.com/keras-team/keras-contrib.git\n","  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-2pznj0fq\n","  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-2pznj0fq\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n","Building wheels for collected packages: keras-contrib\n","  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=47dbe62dc7323f301b64ce823756afca539c9bbe12fff22625c4d6da750218b8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-q5_v5nqp/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n","Successfully built keras-contrib\n","Installing collected packages: keras-contrib\n","Successfully installed keras-contrib-2.0.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yjgw5mtKvKGh","colab_type":"code","colab":{}},"source":["model = Model(input_text, out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wm1LoXNhx5LH","colab_type":"code","colab":{}},"source":["model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l4MdoEa5yFY9","colab_type":"text"},"source":["We need to make the number of samples divisible by the batch_size to make it work. Otherwise the last batch in keras will break the architecture"]},{"cell_type":"code","metadata":{"id":"MG5Zcgjwx-AD","colab_type":"code","colab":{}},"source":["X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\n","y_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\n","y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n","y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iNWP9WlpyQ_S","colab_type":"text"},"source":["Training the model"]},{"cell_type":"code","metadata":{"id":"IzMXYv2IyNbE","colab_type":"code","colab":{}},"source":["history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),\n","                    batch_size=batch_size, epochs=1, verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hYP7EqAFyWPm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}